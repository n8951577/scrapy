1.

import scrapy
class olxspider(scrapy.Spider):

	name="olx"
def start_requests(self):
    urls=[
    'https://www.olx.in/books/'
    'https://www.olx.in/sports-equipment/'
]
    for url in urls:
        yield scrapy.Request(url=url,callback=self.parse)

def parse(self,response):
    page=response.url.split("/")[-2]
    filename='olx-%s.html'%page
    with open(filename,'wb') as f:
        f.write(response.body)
    self.log('Saved file %s' %filename)



2.


import scrapy
class olxSpider(scrapy.Spider):
    name = "olx"
    allowed_urls=["olx.in"]
    start_urls=["https://www.olx.in/books/","https://www.olx.in/sports-equipment/"]

    def parse(self, response):
       filename=response.url.split("/")[-2]
       with open(filename,'wb') as f:
            f.write(response.body)

